# EquiNet

## 项目背景

在金融量化领域，如何利用历史数据预测股票未来走势一直是核心难题。传统方法往往难以捕捉复杂的时序与市场联动特征。EquiNet 基于 Transformer 架构，结合多只股票与大盘数据，致力于专注提升未来3天涨跌概率预测的准确性，本项为学习偏教程项目，任何人可以随意使用。

## 项目简介

 - EquiNet 旨在从0开始构建一个深度学习模型，通过对319只A股股票420天的历史数据进行建模，仅仅使用不到半小时的时间，即可训练出一个具备一定预测能力的模型EquiNet
 - EquiNet 基于 PyTorch 的深度学习项目，支持灵活参数配置和高效GPU训练。通过历史数据建模输出未来3天内股票上涨的概率（0-1之间的连续值）。
 - **最新版本采用二分类方案**：专注于预测股票是否会上涨，输出0-1之间的概率值，更符合实际交易需求。

## 主要特性

- **Transformer 架构**：强大的时序建模能力，适合金融数据。
- **二分类预测**：专注于预测股票是否会上涨，输出0-1之间的概率值。
- **固定评估集**：使用固定的31个测试文件和评估样本，确保评估的一致性和可重复性。
- **灵活参数配置**：支持自定义模型维度、层数、训练轮数等，适应不同硬件与需求。
- **归一化处理**：每只股票独立归一化，消除价格量级影响。
- **GPU加速**：自动检测CUDA，充分利用GPU资源。
- **训练过程评估**：每轮训练后自动评估模型当前预测准确率。
- **断点续训**：自动保存最佳模型权重，便于后续加载与继续训练。
- **实用预测**：专注于预测股票上涨概率，更符合实际交易需求。

## 目录结构

```
EquiNet/
├── data/                # 存放319个.xlsx股票数据文件
├── out/                 # 训练输出的模型权重
├── src/
│   ├── train.py         # 主训练脚本
│   ├── test_model.py    # 模型评估脚本
│   ├── config.py        # 统一配置文件
│   └── ...              # 其他源码
├── README.md
└── ...
```

## 数据格式说明

- 数据目录：`./data`
- 价格区间：1 ~ 6 元
- 每个`.xlsx`文件对应一只股票，包含420天数据，共319只股票。
- 字段说明（共9列）：
  - `time`：日期（如`2023/06/27`）
  - `start`：开盘价
  - `max`：最高价
  - `min`：最低价
  - `end`：收盘价
  - `volume`：股票成交量
  - `marketvolume`：市场总成交量
  - `marketlimit`：大盘涨跌幅（如-1%）
  - `marketrange`：大盘指数波动宽度
- 数据来源：通达信

## 模型输出说明

### 二分类预测
- **输出格式**：0-1之间的连续概率值
- **预测逻辑**：预测未来3天内股票是否会上涨（涨幅≥1%）
- **决策机制**：
  - 概率 > 0.5 → 预测上涨，建议买入
  - 概率 < 0.5 → 预测不上涨，建议不买
- **风险控制**：
  - 保守策略：概率 > 0.7 才买入
  - 平衡策略：概率 > 0.6 买入
  - 激进策略：概率 > 0.5 买入

### 示例输出
```
股票A: 0.85 → 85%概率上涨 → 买入
股票B: 0.35 → 35%概率上涨 → 不买
股票C: 0.62 → 62%概率上涨 → 买入
```

## 安装与环境

- Python 3.8+
- PyTorch
- pandas、numpy
- tqdm

安装依赖：
```bash
pip install torch pandas numpy tqdm
```

## 使用流程

### 快速开始
1. **克隆项目**
   ```bash
   git clone https://gitee.com/hujiyo/EquiNet.git
   ```

2. **运行训练脚本**
   ```bash
   python src/train.py
   ```

3. **模型评估**
   - 训练完成后，模型权重保存在`./out/EnhancedEquiNet_{d_model}.pth`。
   - 可使用`src/test_model.py`对模型进行评估：
     ```bash
     python src/test_model.py
     ```

### 训练结果示例
```
Epoch 54 评估结果:
  不上涨: 83/110 = 0.755
  上涨: 33/90 = 0.367
  总体准确率: 0.580
  评估得分: 60.5 / 200 = 0.302
```

### 常规训练流程
1. **准备数据**
   - 将319个`.xlsx`股票数据文件放入`./data`目录下。

2. **运行训练脚本**
   ```bash
   python src/train.py
   ```
   - 程序会自动使用配置文件中的参数进行训练。
   - 训练过程中显示进度、损失、学习率及每轮评估准确率。

3. **模型评估**
   - 训练完成后，模型权重保存在`./out/EnhancedEquiNet_{d_model}.pth`。
   - 可使用`src/test_model.py`对模型进行评估：
     ```bash
     python src/test_model.py
     ```

## 配置文件使用说明

<details>
<summary><strong>📋 点击展开：配置文件详细使用说明</strong></summary>

### 概述

`config.py` 是 EquiNet 项目的统一配置文件，用于管理模型参数、训练参数和评估参数。通过这个配置文件，您可以轻松地调整模型的各种设置，而无需修改多个文件。

### 配置文件结构

配置文件包含以下几个主要部分：

#### 1. 模型架构参数 (ModelConfig)
- **基础模型参数**: 输入维度、模型维度、注意力头数、层数等
- **位置编码参数**: 时间衰减因子
- **注意力机制参数**: Dropout比率
- **专业化注意力头分配**: 价格、成交量、波动率、模式头数量
- **多尺度注意力参数**: 短期、中期、长期窗口设置

#### 2. 训练参数 (TrainingConfig)
- **基础训练参数**: 训练轮数、学习率、批处理大小
- **优化器参数**: 权重衰减、梯度裁剪
- **学习率调度器参数**: 步长、衰减因子
- **损失函数参数**: Focal Loss的alpha和gamma参数
- **动态权重调整参数**: 窗口大小、权重范围

#### 3. 数据参数 (DataConfig)
- **数据路径**: 数据目录、输出目录
- **数据分割参数**: 测试集比例、随机种子
- **样本生成参数**: 历史数据长度、预测天数
- **二分类阈值**: 上涨阈值（1%）
- **评估参数**: 评估样本数量

#### 4. 评估参数 (EvaluationConfig)
- **评分规则**: 正确预测得分、假阳性惩罚、假阴性惩罚
- **评估设置**: 评估样本数、批处理大小

#### 5. 设备配置 (DeviceConfig)
- **设备管理**: 自动检测GPU/CPU
- **设备信息**: 打印设备信息

#### 6. 模型保存配置 (ModelSaveConfig)
- **模型文件名**: 最佳模型、最终模型文件名
- **路径管理**: 获取模型保存路径

### 使用方法

#### 1. 查看当前配置
```bash
python src/config.py
```

#### 2. 修改配置参数
直接编辑 `src/config.py` 文件中的相应参数值。例如：

```python
# 修改训练参数
TrainingConfig.EPOCHS = 100                    # 增加训练轮数
TrainingConfig.LEARNING_RATE = 0.0005          # 降低学习率

# 修改模型参数
ModelConfig.D_MODEL = 256                       # 增加模型维度
ModelConfig.NHEAD = 16                          # 增加注意力头数

# 修改数据参数
DataConfig.CONTEXT_LENGTH = 90                  # 增加历史数据长度
DataConfig.UPRISE_THRESHOLD = 0.05              # 调整大涨阈值
```

#### 3. 查看配置摘要
```bash
python src/config.py
```
系统会打印当前配置摘要。

#### 4. 运行训练
```bash
python src/train.py
```
训练脚本会自动使用配置文件中的参数。

#### 5. 测试模型
```bash
python src/test_model.py
```
测试脚本也会使用配置文件中的参数。

### 常用参数调整

#### 提高模型性能
```python
# 增加模型复杂度
ModelConfig.D_MODEL = 256
ModelConfig.NHEAD = 16
ModelConfig.NUM_LAYERS = 6

# 调整训练参数
TrainingConfig.EPOCHS = 100
TrainingConfig.LEARNING_RATE = 0.0005
TrainingConfig.BATCH_SIZE = 32
```

#### 加快训练速度
```python
# 减少模型复杂度
ModelConfig.D_MODEL = 64
ModelConfig.NHEAD = 4
ModelConfig.NUM_LAYERS = 2

# 调整训练参数
TrainingConfig.BATCH_SIZE = 100
TrainingConfig.BATCHES_PER_EPOCH = 10
```

#### 处理类别不平衡
```python
# 调整二分类Focal Loss参数
TrainingConfig.FOCAL_LOSS_ALPHA = [1.0, 1.0]  # 平衡权重
TrainingConfig.FOCAL_LOSS_GAMMA = 2.0

# 调整上涨阈值
DataConfig.UPRISE_THRESHOLD = 0.01  # 1%上涨阈值
```

#### 调整评估策略
```python
# 修改评分规则
EvaluationConfig.CORRECT_PREDICTION_SCORE = 2
EvaluationConfig.FALSE_POSITIVE_PENALTY = -1
EvaluationConfig.FALSE_NEGATIVE_PENALTY = -0.5

# 增加评估样本
EvaluationConfig.EVAL_SAMPLES = 2000
```

### 参数修改示例

以下是一些常见的参数修改示例：

#### 提高模型性能
```python
# 增加模型复杂度
ModelConfig.D_MODEL = 256
ModelConfig.NHEAD = 16
ModelConfig.NUM_LAYERS = 6

# 调整训练参数
TrainingConfig.EPOCHS = 100
TrainingConfig.LEARNING_RATE = 0.0005
TrainingConfig.BATCH_SIZE = 32
```

#### 加快训练速度
```python
# 减少模型复杂度
ModelConfig.D_MODEL = 64
ModelConfig.NHEAD = 4
ModelConfig.NUM_LAYERS = 2

# 调整训练参数
TrainingConfig.BATCH_SIZE = 100
TrainingConfig.BATCHES_PER_EPOCH = 10
```

#### 处理类别不平衡
```python
# 调整二分类Focal Loss参数
TrainingConfig.FOCAL_LOSS_ALPHA = [1.0, 1.0]  # 平衡权重
TrainingConfig.FOCAL_LOSS_GAMMA = 2.0

# 调整上涨阈值
DataConfig.UPRISE_THRESHOLD = 0.01  # 1%上涨阈值
```

#### 调整评估策略
```python
# 修改评分规则
EvaluationConfig.CORRECT_PREDICTION_SCORE = 2
EvaluationConfig.FALSE_POSITIVE_PENALTY = -1
EvaluationConfig.FALSE_NEGATIVE_PENALTY = -0.5

# 增加评估样本
EvaluationConfig.EVAL_SAMPLES = 2000
```

### 注意事项

1. **参数一致性**: 确保训练和测试时使用相同的配置参数
2. **内存限制**: 增加模型维度时注意GPU内存限制
3. **训练时间**: 增加训练轮数或模型复杂度会显著增加训练时间
4. **数据质量**: 调整类别阈值可能影响数据质量和模型性能

### 故障排除

#### 常见问题

1. **参数设置错误**: 检查参数设置是否合理，特别是模型维度与注意力头数的关系
2. **内存不足**: 减少批处理大小或模型维度
3. **训练速度慢**: 增加批处理大小或减少模型复杂度
4. **模型性能差**: 调整学习率、增加训练轮数或模型复杂度

#### 调试建议

1. 先使用默认配置运行，确保系统正常工作
2. 逐步调整参数，观察对性能的影响
3. 使用 `config.py` 查看配置摘要
4. 记录不同配置下的性能表现

### 版本历史

- **v1.0**: 初始版本，包含基本的模型、训练、数据和评估参数
- **v1.1**: 添加了参数验证和配置摘要功能
- **v1.2**: 增加了设备配置和模型保存配置
- **v1.3**: 添加了使用示例和详细文档

</details>

## 项目修改LOG

- 2025.6.1: **重大更新** - 采用二分类方案，专注于预测股票是否会上涨，输出0-1之间的概率值，更符合实际交易需求。使用固定的31个测试文件和评估样本，确保评估的一致性和可重复性。模型准确率达到58%，接近60%目标。
- 2025.6.1: **架构优化** - 重新设计模型架构，增加模型维度(128)和层数(3)，优化注意力头分配(价格3头、成交量2头、波动率2头、模式1头)，使用时间感知注意力机制，提升模型表达能力。
- 2025.5.31:积分制成为默认机制，增加时间感知位置编码、Focal Loss损失函数、结合标准正弦余弦位置编码、指数衰减机制、种类差异化多头注意力机制、多尺度注意力，加入了残差连接和层归一化。
- 2025.5.12:增加mark积分制判别最优模型,但保留原判别机制
- 2025.5.1:项目start ~

## 参与贡献

1. Fork 本仓库
2. 新建分支（如 `dev_yourname`）
3. 提交代码
4. 新建 Pull Request

## 联系方式

- 邮箱: hj18914255909@outlook.com

## 致谢

1. 感谢通达信提供的股票数据（虽然我是买了初级会员才获得的数据的~QvQ~）。
2. 项目当前以及未来的所有代码均会是在QwQ-32b、豆包、deepseek、ChatGPT等等大佬的帮助下完成的，在此表示感谢。
最初对QwQ的prompt：
```
背景介绍：现在你在进行一个利用python进行模型训练的2030年编程比赛，参赛者有中国昔日之光：deepseek-r1:671b满血版、openAI最新编程大神：ChatGPT6.0:9600b世界版、千问推理模型QwQ-32b（你）......注意，你可以无限长时间循环分步骤思考，但是你的机会只有一次！
现在是试卷的最后一题：在./下写一个.py模型训练程序，模型数据存放在./data下，那里有着319个.xlsx文件，每个文件对应一只股票，每个文件的有效行数为421行，其中第一行也就是表头字段分别有time	start	max	min	end	volume	marketvolume	marketlimit	marketrange这9个字段，2-421行都是数据，也就是说每个文件实际上都是包含一只股票420天的基本情况和当天大盘的情况。每个文件的time都是420天并且初始日期都是对照相同的，start/end	是开/收盘价，max/min是最高/低价，volume是股票量能，marketvolume是市场量能，marketlimit是大盘涨跌幅，marketrange是大盘指数的波动宽度，（比如marketlimit为-1%，marketrange为50，则暗示大盘下跌30个点，宽度在50个点，波动很大）	模型的输出结果是对未来3天的情况进行概率预测，分别是上涨3%的概率，下跌2%的概率，保持-2%~3%的概率，例如输出：涨5%：\n跌3%：54%，\n稳：25%。
提示：
1.建议使用transformer架构，程序开始需要提示用户输入想要的模型训练的大小参数和训练轮次。为避免用户不懂，你还要有提示信息（比如对最终模型效果的影响、对模型最终参数量的影响等等）
2.训练过程中，使用随机上下文长度（20天-100天），这种随机效果可以变相降低数据量有限的弊端，然后对下面3天进行预测
3.训练过程中要给出进度信息（包括学习率），每轮训练结束后要增加一个效果环节，具体如下：用相同的方法从数据中随机获得片段作为输入然后，将概率大的视为模型的选择，循环多次即可计算出当前模型预测成功的概率并打印。
4.不同股票的价格不同，模型的目标是掌握其中更深层次的规律，所以训练数据要进行统一的归一化
5.使用支持CUDA的gpu进行训练
6.time字段的格式为'2023/06/27'
7.不要提前确定好所有的数据然后轮流开始训练，这违背了我随机思想的初衷，我要的是训练输入上的完全随机，每轮1000组随机输入
```

## 术语解释（持续更新）

- `残差连接`: 简单理解就是把输入直接"跳过"一些层加到输出上，对解决`梯度消失`问题有帮助，让训练更稳定（即使某一层学坏了，至少原始信息还能通过"跳跃连接"传递下去），确保重要信息不易丢失，更容易优化（网络可以学习"在原有基础上做什么改进"，而不是"从零开始学一切"）

- `层归一化`: 简单理解就是把每一层的输出"标准化"，让数值分布更稳定（防止某些神经元输出过大或过小），加速收敛（让梯度更平滑，模型收敛更快？）

- `Focal Loss`:一种解决one-stage目标检测中正负样本数量极不平衡问题的损失函数，比如：股票中上涨的样本远远小于稳定的样本，这个时候稳定的样本的规律信息就可能会淹没上涨样本提供的信息，对于股票来说，样本不平衡问题是常态。

- `二分类预测`: 将复杂的多分类问题简化为二分类问题，专注于预测股票是否会上涨。输出0-1之间的概率值，更直观易懂，符合实际交易决策需求。

- `固定评估集`: 使用固定的测试文件和评估样本，确保每次评估使用相同的样本，提高评估结果的可重复性和可比性。

