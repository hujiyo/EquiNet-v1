"""
run_the_stock.py - å•è‚¡ç¥¨å†å²é¢„æµ‹éªŒè¯å·¥å…·

åŠŸèƒ½ï¼š
1. è¾“å…¥è‚¡ç¥¨ä»£ç ï¼Œæ‰¾åˆ°å¯¹åº”çš„xlsxæ–‡ä»¶
2. è¾“å…¥æ—¥æœŸï¼ˆå¦‚2025/01/17ï¼‰ï¼Œä»¥è¯¥æ—¥æœŸä¸ºåˆ†æ°´å²­
3. ä½¿ç”¨out_stableä¸‹çš„4ä¸ªæ¨¡å‹é¢„æµ‹æœªæ¥3å¤©
4. æ‰“å°å®é™…æ¶¨è·Œæƒ…å†µ
"""

import os
import torch
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from train import EnhancedStockTransformer
from config import ModelConfig, DataConfig, DeviceConfig

def find_stock_file(stock_code, data_dirs=['./today', './data', './data_new']):
    """
    æ ¹æ®è‚¡ç¥¨ä»£ç æŸ¥æ‰¾å¯¹åº”çš„xlsxæ–‡ä»¶
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 000034 æˆ– 000034.xlsxï¼‰
        data_dirs: è¦æœç´¢çš„ç›®å½•åˆ—è¡¨
        
    Returns:
        str: æ–‡ä»¶å®Œæ•´è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å›None
    """
    # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
    if not stock_code.endswith('.xlsx'):
        stock_code = stock_code + '.xlsx'
    
    # åœ¨æ‰€æœ‰ç›®å½•ä¸­æœç´¢
    for data_dir in data_dirs:
        if not os.path.exists(data_dir):
            continue
        
        file_path = os.path.join(data_dir, stock_code)
        if os.path.exists(file_path):
            return file_path
    
    return None

def load_stock_data(file_path):
    """
    åŠ è½½è‚¡ç¥¨æ•°æ®
    
    Returns:
        tuple: (df, data, time_column)
    """
    df = pd.read_excel(file_path, engine='openpyxl')
    
    # æ£€æŸ¥å¿…éœ€çš„åˆ—
    required_columns = ['time', 'start', 'max', 'min', 'end', 'volume']
    for col in required_columns:
        if col not in df.columns:
            raise ValueError(f"æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„åˆ—: {col}")
    
    # è½¬æ¢æ—¶é—´åˆ— - è‡ªåŠ¨è¯†åˆ«æ ¼å¼ï¼Œä¸æŒ‡å®šformatå‚æ•°
    df['time'] = pd.to_datetime(df['time'], errors='coerce')
    
    # åˆ é™¤æ—¶é—´åˆ—ä¸­çš„æ— æ•ˆå€¼ï¼ˆNaTï¼‰
    original_len = len(df)
    df = df.dropna(subset=['time']).reset_index(drop=True)
    if original_len > len(df):
        print(f"  âš  å·²ç§»é™¤ {original_len - len(df)} è¡Œæ— æ•ˆæ—¥æœŸæ•°æ®")
    
    if len(df) == 0:
        raise ValueError("æ•°æ®æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ—¥æœŸæ•°æ®ï¼Œè¯·æ£€æŸ¥timeåˆ—çš„æ ¼å¼")
    
    # æŒ‰æ—¶é—´æ’åºï¼ˆç¡®ä¿ä»æ—§åˆ°æ–°ï¼‰
    df = df.sort_values('time', ascending=True).reset_index(drop=True)
    
    # æå–OHLCVæ•°æ®
    data = df[['start', 'max', 'min', 'end', 'volume']].values
    time_column = df['time'].values
    
    return df, data, time_column

def find_date_index(time_column, target_date):
    """
    æŸ¥æ‰¾ç›®æ ‡æ—¥æœŸåœ¨æ—¶é—´åˆ—ä¸­çš„ç´¢å¼•
    
    Args:
        time_column: æ—¶é—´åˆ—ï¼ˆnumpy array of datetime64ï¼‰
        target_date: ç›®æ ‡æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆå¦‚ "2025/01/17" æˆ– "2025-01-17"ï¼‰
        
    Returns:
        int: ç´¢å¼•ä½ç½®ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å›-1
    """
    try:
        # è‡ªåŠ¨è¯†åˆ«æ—¥æœŸæ ¼å¼
        target = pd.to_datetime(target_date)
    except:
        return -1
    
    # æŸ¥æ‰¾ç²¾ç¡®åŒ¹é…
    for i, t in enumerate(time_column):
        if pd.Timestamp(t).date() == target.date():
            return i
    
    return -1

def predict_with_model(model_path, input_data, device):
    """
    ä½¿ç”¨å•ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼Œç›´æ¥è°ƒç”¨ç»Ÿä¸€é¢„æµ‹å‡½æ•°ï¼‰
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        input_data: è¾“å…¥æ•°æ®ï¼ˆæ ‡å‡†åŒ–åçš„OHLCVï¼Œé•¿åº¦ç”±CONTEXT_LENGTHé…ç½®ï¼‰
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        float: é¢„æµ‹æ¦‚ç‡
    """
    # æ³¨æ„ï¼šinput_dataå·²ç»æ˜¯æ ‡å‡†åŒ–åçš„æ•°æ®ï¼Œéœ€è¦æ„é€ åŸå§‹æ•°æ®æ ¼å¼
    # ç”±äºç»Ÿä¸€é¢„æµ‹å‡½æ•°å†…éƒ¨ä¼šé‡æ–°æ ‡å‡†åŒ–ï¼Œè¿™é‡Œéœ€è¦ç‰¹æ®Šå¤„ç†
    # ä¸ºäº†ä¿æŒå…¼å®¹æ€§ï¼Œè¿™é‡Œä¿æŒåŸæœ‰å®ç°
    
    # åŠ è½½æ¨¡å‹
    model = EnhancedStockTransformer(
        input_dim=ModelConfig.INPUT_DIM,
        d_model=ModelConfig.D_MODEL,
        nhead=ModelConfig.NHEAD,
        num_layers=ModelConfig.NUM_LAYERS,
        output_dim=ModelConfig.OUTPUT_DIM,
        max_seq_len=ModelConfig.MAX_SEQ_LEN
    ).to(device)
    
    model = model.to(dtype=torch.bfloat16)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    
    # é¢„æµ‹
    with torch.no_grad():
        input_tensor = torch.tensor(input_data, dtype=torch.bfloat16).unsqueeze(0).to(device)
        output = model(input_tensor)
        probability = torch.sigmoid(output).float().cpu().item()
    
    return probability

def calculate_actual_return(data, start_idx, future_days=3):
    """
    è®¡ç®—å®é™…æ”¶ç›Šç‡
    
    Args:
        data: åŸå§‹OHLCVæ•°æ®
        start_idx: èµ·å§‹ç´¢å¼•ï¼ˆé¢„æµ‹æ—¥çš„ç´¢å¼•ï¼‰
        future_days: æœªæ¥å¤©æ•°
        
    Returns:
        tuple: (actual_return, start_price, end_price)
    """
    if start_idx + future_days >= len(data):
        return None, None, None
    
    start_price = data[start_idx, 3]  # å½“å‰æ”¶ç›˜ä»·
    end_price = data[start_idx + future_days, 3]  # 3å¤©åæ”¶ç›˜ä»·
    
    if start_price == 0:
        return None, None, None
    
    actual_return = (end_price - start_price) / start_price
    
    return actual_return, start_price, end_price

def get_date_range_info(time_column, start_idx, context_length=None, future_days=None):
    """
    è·å–æ—¥æœŸèŒƒå›´ä¿¡æ¯
    
    Returns:
        dict: åŒ…å«è¾“å…¥æ•°æ®æ—¥æœŸèŒƒå›´å’Œé¢„æµ‹ç›®æ ‡æ—¥æœŸèŒƒå›´çš„ä¿¡æ¯
    """
    # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼
    if context_length is None:
        context_length = DataConfig.CONTEXT_LENGTH
    if future_days is None:
        future_days = DataConfig.FUTURE_DAYS
    
    info = {}
    
    # è¾“å…¥æ•°æ®çš„æ—¥æœŸèŒƒå›´ï¼ˆå†å²æ•°æ®ï¼‰
    if start_idx - context_length + 1 >= 0:
        input_start_date = pd.Timestamp(time_column[start_idx - context_length + 1]).strftime('%Y/%m/%d')
        input_end_date = pd.Timestamp(time_column[start_idx]).strftime('%Y/%m/%d')
        info['input_range'] = f"{input_start_date} è‡³ {input_end_date}"
    else:
        info['input_range'] = "æ•°æ®ä¸è¶³"
    
    # é¢„æµ‹ç›®æ ‡çš„æ—¥æœŸèŒƒå›´ï¼ˆæœªæ¥3å¤©ï¼‰
    if start_idx + future_days < len(time_column):
        predict_start_date = pd.Timestamp(time_column[start_idx]).strftime('%Y/%m/%d')
        predict_end_date = pd.Timestamp(time_column[start_idx + future_days]).strftime('%Y/%m/%d')
        info['predict_range'] = f"{predict_start_date} â†’ {predict_end_date}"
        info['predict_end_date'] = predict_end_date
    else:
        info['predict_range'] = "æœªæ¥æ•°æ®ä¸è¶³"
        info['predict_end_date'] = "æœªçŸ¥"
    
    return info

def print_day_by_day_details(df, start_idx, future_days=3):
    """
    æ‰“å°é€æ—¥è¯¦ç»†æ•°æ®
    
    Args:
        df: å®Œæ•´çš„DataFrameï¼ˆåŒ…å«timeåˆ—ï¼‰
        start_idx: èµ·å§‹ç´¢å¼•
        future_days: æœªæ¥å¤©æ•°
    """
    print(f"\n{'='*80}")
    print("é€æ—¥è¯¦ç»†æ•°æ®")
    print(f"{'='*80}")
    
    # æ‰“å°è¡¨å¤´
    print(f"{'æ—¥æœŸ':<12} {'å¼€ç›˜':<10} {'æœ€é«˜':<10} {'æœ€ä½':<10} {'æ”¶ç›˜':<10} {'æˆäº¤é‡':<12} {'æ¶¨è·Œå¹…':<10}")
    print("-" * 80)
    
    # å½“å‰æ—¥ï¼ˆé¢„æµ‹èµ·ç‚¹ï¼‰
    current_row = df.iloc[start_idx]
    print(f"{pd.Timestamp(current_row['time']).strftime('%Y/%m/%d'):<12} "
          f"{current_row['start']:<10.2f} "
          f"{current_row['max']:<10.2f} "
          f"{current_row['min']:<10.2f} "
          f"{current_row['end']:<10.2f} "
          f"{int(current_row['volume']):<12} "
          f"{'(åŸºå‡†æ—¥)':<10}")
    
    base_price = current_row['end']
    
    # æœªæ¥æ¯ä¸€å¤©
    for i in range(1, future_days + 1):
        if start_idx + i >= len(df):
            print(f"ç¬¬{i}å¤©: æ•°æ®ä¸è¶³")
            continue
        
        row = df.iloc[start_idx + i]
        day_return = (row['end'] - base_price) / base_price * 100
        
        # é¢œè‰²æ ‡è®°ï¼ˆç”¨ç¬¦å·è¡¨ç¤ºï¼‰
        if day_return > 0:
            change_str = f"+{day_return:.2f}%"
        elif day_return < 0:
            change_str = f"{day_return:.2f}%"
        else:
            change_str = f"{day_return:.2f}%"
        
        print(f"{pd.Timestamp(row['time']).strftime('%Y/%m/%d'):<12} "
              f"{row['start']:<10.2f} "
              f"{row['max']:<10.2f} "
              f"{row['min']:<10.2f} "
              f"{row['end']:<10.2f} "
              f"{int(row['volume']):<12} "
              f"{change_str:<10}")
    
    print("-" * 80)

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®å·¥ä½œç›®å½•
    os.chdir(os.path.dirname(os.path.abspath(__file__)))
    
    # è·å–è®¾å¤‡
    device = DeviceConfig.get_device()
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    if device.type == "cuda":
        print(f"GPU: {torch.cuda.get_device_name()}")
    print()
    
    # æ£€æŸ¥out_stableç›®å½•
    model_dir = './out_stable'
    if not os.path.exists(model_dir):
        print(f"é”™è¯¯ï¼š{model_dir} æ–‡ä»¶å¤¹ä¸å­˜åœ¨")
        print("è¯·ç¡®ä¿out_stableæ–‡ä»¶å¤¹å­˜åœ¨å¹¶åŒ…å«æ¨¡å‹æ–‡ä»¶")
        return
    
    # è·å–æ¨¡å‹æ–‡ä»¶
    model_files = sorted([f for f in os.listdir(model_dir) if f.endswith('.pth')])
    
    if len(model_files) == 0:
        print(f"é”™è¯¯ï¼š{model_dir} æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ¨¡å‹æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹:")
    for i, f in enumerate(model_files, 1):
        print(f"  {i}. {f}")
    print()
    
    # è¾“å…¥è‚¡ç¥¨ä»£ç 
    print("=" * 80)
    stock_code = input("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 000034 æˆ– 000034.xlsxï¼‰: ").strip()
    
    if not stock_code:
        print("é”™è¯¯ï¼šè‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º")
        return
    
    # æŸ¥æ‰¾è‚¡ç¥¨æ–‡ä»¶
    print(f"\næ­£åœ¨æŸ¥æ‰¾è‚¡ç¥¨æ–‡ä»¶...")
    file_path = find_stock_file(stock_code)
    
    if file_path is None:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°è‚¡ç¥¨ {stock_code} çš„æ•°æ®æ–‡ä»¶")
        print("å·²æœç´¢ç›®å½•: ./today, ./data, ./data_new")
        return
    
    print(f"âœ“ æ‰¾åˆ°æ–‡ä»¶: {file_path}")
    
    # åŠ è½½è‚¡ç¥¨æ•°æ®
    print(f"\næ­£åœ¨åŠ è½½è‚¡ç¥¨æ•°æ®...")
    try:
        df, data, time_column = load_stock_data(file_path)
        print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"  æ•°æ®é•¿åº¦: {len(data)} å¤©")
        
        # å®‰å…¨åœ°æ‰“å°æ—¥æœŸèŒƒå›´
        try:
            start_date = pd.Timestamp(time_column[0]).strftime('%Y/%m/%d')
            end_date = pd.Timestamp(time_column[-1]).strftime('%Y/%m/%d')
            print(f"  æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
        except Exception as date_error:
            print(f"  âš  æ— æ³•æ˜¾ç¤ºæ—¥æœŸèŒƒå›´: {date_error}")
    except Exception as e:
        print(f"é”™è¯¯ï¼šåŠ è½½æ•°æ®å¤±è´¥ - {e}")
        import traceback
        traceback.print_exc()
        return
    
    # è¾“å…¥ç›®æ ‡æ—¥æœŸ
    print("\n" + "=" * 80)
    target_date = input("è¯·è¾“å…¥ç›®æ ‡æ—¥æœŸï¼ˆæ ¼å¼: 2025/01/17ï¼‰: ").strip()
    
    if not target_date:
        print("é”™è¯¯ï¼šæ—¥æœŸä¸èƒ½ä¸ºç©º")
        return
    
    # æŸ¥æ‰¾æ—¥æœŸç´¢å¼•
    print(f"\næ­£åœ¨æŸ¥æ‰¾æ—¥æœŸ {target_date}...")
    date_idx = find_date_index(time_column, target_date)
    
    if date_idx == -1:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ—¥æœŸ {target_date}")
        print(f"å¯ç”¨æ—¥æœŸèŒƒå›´: {pd.Timestamp(time_column[0]).strftime('%Y/%m/%d')} è‡³ {pd.Timestamp(time_column[-1]).strftime('%Y/%m/%d')}")
        return
    
    print(f"âœ“ æ‰¾åˆ°æ—¥æœŸï¼Œç´¢å¼•ä½ç½®: {date_idx}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
    context_length = DataConfig.CONTEXT_LENGTH
    if date_idx < context_length - 1:
        print(f"é”™è¯¯ï¼šå†å²æ•°æ®ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘{context_length}å¤©ï¼Œå½“å‰åªæœ‰{date_idx + 1}å¤©ï¼‰")
        return
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœªæ¥æ•°æ®ï¼ˆç”¨äºéªŒè¯ï¼‰
    future_days = DataConfig.FUTURE_DAYS  # 3å¤©
    if date_idx + future_days >= len(data):
        print(f"è­¦å‘Šï¼šæœªæ¥æ•°æ®ä¸è¶³ï¼ˆéœ€è¦{future_days}å¤©ï¼Œåªæœ‰{len(data) - date_idx - 1}å¤©ï¼‰ï¼Œæ— æ³•éªŒè¯å®é™…ç»“æœ")
        has_future_data = False
    else:
        has_future_data = True
    
    # è·å–æ—¥æœŸèŒƒå›´ä¿¡æ¯
    date_info = get_date_range_info(time_column, date_idx, context_length, future_days)
    
    # å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆå†å²æ•°æ®ï¼‰
    print(f"\næ­£åœ¨å‡†å¤‡è¾“å…¥æ•°æ®...")
    input_start_idx = date_idx - context_length + 1
    input_data_raw = data[input_start_idx:date_idx + 1]  # context_lengthå¤©
    
    print(f"  è¾“å…¥æ•°æ®èŒƒå›´: {date_info['input_range']}")
    print(f"  é¢„æµ‹ç›®æ ‡èŒƒå›´: {date_info['predict_range']}")
    
    # ğŸ”‘ ä¿®å¤ï¼šä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ»šåŠ¨çª—å£æ ‡å‡†åŒ–
    # é¿å…è®­ç»ƒ-é¢„æµ‹ä¸ä¸€è‡´çš„é—®é¢˜
    input_data_normalized = np.zeros_like(input_data_raw, dtype=np.float64)
    
    if len(input_data_raw) < 2:
        print(f"é”™è¯¯ï¼šæ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ»šåŠ¨çª—å£æ ‡å‡†åŒ–")
        return
    
    # æ»šåŠ¨çª—å£æ ‡å‡†åŒ–ï¼šæ¯å¤©ç›¸å¯¹äºå‰ä¸€å¤©çš„æ¶¨è·Œå¹…
    valid_data = True
    for i in range(1, len(input_data_raw)):
        yesterday_close = input_data_raw[i-1, 3]  # å‰ä¸€å¤©çš„æ”¶ç›˜ä»·
        yesterday_volume = input_data_raw[i-1, 4]  # å‰ä¸€å¤©çš„æˆäº¤é‡
        
        if yesterday_close == 0 or yesterday_volume == 0:
            print(f"é”™è¯¯ï¼šç¬¬{i}å¤©æ•°æ®å¼‚å¸¸ï¼ˆä»·æ ¼æˆ–æˆäº¤é‡ä¸º0ï¼‰")
            valid_data = False
            break
        
        # ä»·æ ¼ç‰¹å¾ï¼šç›¸å¯¹äºå‰ä¸€å¤©æ”¶ç›˜ä»·çš„æ¶¨è·Œå¹…
        input_data_normalized[i, :4] = (input_data_raw[i, :4] - yesterday_close) / yesterday_close
        # æˆäº¤é‡ç‰¹å¾ï¼šç›¸å¯¹äºå‰ä¸€å¤©æˆäº¤é‡çš„å˜åŒ–æ¯”ä¾‹
        input_data_normalized[i, 4] = (input_data_raw[i, 4] - yesterday_volume) / yesterday_volume
    
    if not valid_data:
        return
    
    # åªä½¿ç”¨æ ‡å‡†åŒ–åçš„æ•°æ®ï¼ˆå»æ‰ç¬¬0å¤©åŸºå‡†æ•°æ®ï¼‰
    input_data_normalized = input_data_normalized[1:]
    
    # ä½¿ç”¨æ‰€æœ‰æ¨¡å‹è¿›è¡Œé¢„æµ‹
    print(f"\n{'='*80}")
    print("æ¨¡å‹é¢„æµ‹ç»“æœ")
    print(f"{'='*80}")
    
    predictions = []
    
    for model_file in model_files:
        model_path = os.path.join(model_dir, model_file)
        
        try:
            print(f"\næ­£åœ¨ä½¿ç”¨æ¨¡å‹: {model_file}")
            probability = predict_with_model(model_path, input_data_normalized, device)
            predictions.append((model_file, probability))
            
            # åˆ¤æ–­é¢„æµ‹ç»“æœ
            if probability >= 0.9:
                suggestion = "å»ºè®®è´­ä¹°"
            elif probability >= 0.8:
                suggestion = "è°¨æ…ä¹°å…¥"
            else:
                suggestion = ""
            
            print(f"  é¢„æµ‹æ¦‚ç‡: {probability:.4f} {suggestion}")
            
        except Exception as e:
            print(f"  âœ— é¢„æµ‹å¤±è´¥: {e}")
            continue
    
    # è®¡ç®—é¢„æµ‹ç»Ÿè®¡
    if len(predictions) > 0:
        avg_prob = np.mean([p[1] for p in predictions])
        max_prob = max([p[1] for p in predictions])
        min_prob = min([p[1] for p in predictions])
        std_prob = np.std([p[1] for p in predictions])
        
        print(f"\n{'='*80}")
        print("é¢„æµ‹ç»Ÿè®¡")
        print(f"{'='*80}")
        print(f"å‚ä¸æ¨¡å‹æ•°: {len(predictions)}")
        print(f"å¹³å‡æ¦‚ç‡: {avg_prob:.4f}")
        print(f"æœ€é«˜æ¦‚ç‡: {max_prob:.4f} ({[p[0] for p in predictions if p[1] == max_prob][0]})")
        print(f"æœ€ä½æ¦‚ç‡: {min_prob:.4f} ({[p[0] for p in predictions if p[1] == min_prob][0]})")
        print(f"æ ‡å‡†å·®: {std_prob:.4f}")
        
        # ç»¼åˆå»ºè®®
        if avg_prob >= 0.9:
            consensus = "å¼ºçƒˆå»ºè®®è´­ä¹°ï¼ˆå¤šæ¨¡å‹ä¸€è‡´çœ‹å¥½ï¼‰"
        elif avg_prob >= 0.8:
            consensus = "è°¨æ…ä¹°å…¥ï¼ˆå¤šæ¨¡å‹è¾ƒä¸ºçœ‹å¥½ï¼‰"
        elif avg_prob >= 0.7:
            consensus = "è§‚æœ›ï¼ˆæ¨¡å‹æ„è§ä¸ä¸€è‡´ï¼‰"
        else:
            consensus = "ä¸å»ºè®®è´­ä¹°"
        
        print(f"\nç»¼åˆå»ºè®®: {consensus}")
    
    # æ‰“å°å®é™…æƒ…å†µ
    if has_future_data:
        print(f"\n{'='*80}")
        print("å®é™…æƒ…å†µéªŒè¯")
        print(f"{'='*80}")
        
        actual_return, start_price, end_price = calculate_actual_return(data, date_idx, future_days)
        
        if actual_return is not None:
            print(f"åŸºå‡†æ—¥æœŸ ({target_date}): æ”¶ç›˜ä»· = {start_price:.2f}")
            print(f"ç›®æ ‡æ—¥æœŸ ({date_info['predict_end_date']}): æ”¶ç›˜ä»· = {end_price:.2f}")
            print(f"å®é™…æ¶¨è·Œå¹…: {actual_return * 100:.2f}%")
            
            # åˆ¤æ–­å®é™…ç»“æœ
            uprise_threshold = DataConfig.UPRISE_THRESHOLD
            if actual_return >= uprise_threshold:
                actual_label = f"ä¸Šæ¶¨ (â‰¥{uprise_threshold*100}%)"
                result_icon = "âœ“"
            else:
                actual_label = f"æœªè¾¾æ ‡ (<{uprise_threshold*100}%)"
                result_icon = "âœ—"
            
            print(f"å®é™…ç»“æœ: {result_icon} {actual_label}")
            
            # æ¨¡å‹é¢„æµ‹éªŒè¯
            if len(predictions) > 0:
                correct_count = 0
                for model_file, probability in predictions:
                    predicted_up = probability >= 0.5
                    actual_up = actual_return >= uprise_threshold
                    
                    if predicted_up == actual_up:
                        correct_count += 1
                
                accuracy = correct_count / len(predictions)
                print(f"\næ¨¡å‹é¢„æµ‹å‡†ç¡®åº¦: {correct_count}/{len(predictions)} = {accuracy:.1%}")
            
            # æ‰“å°é€æ—¥è¯¦ç»†æ•°æ®
            print_day_by_day_details(df, date_idx, future_days)
        else:
            print("æ— æ³•è®¡ç®—å®é™…æ”¶ç›Šç‡ï¼ˆæ•°æ®å¼‚å¸¸ï¼‰")
    else:
        print(f"\n{'='*80}")
        print("å®é™…æƒ…å†µéªŒè¯")
        print(f"{'='*80}")
        print("æœªæ¥æ•°æ®ä¸è¶³ï¼Œæ— æ³•éªŒè¯å®é™…ç»“æœ")
        print(f"éœ€è¦æ—¥æœŸ {target_date} ä¹‹åè‡³å°‘ {future_days} å¤©çš„æ•°æ®")
    
    print(f"\n{'='*80}")
    print("åˆ†æå®Œæˆï¼")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()

